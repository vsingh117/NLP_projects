{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - N-Grams Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import udhr\n",
    "import re\n",
    "import collections\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import random\n",
    "import string\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Train and Test Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text = list(pd.read_csv('../data/CONcreTEXT_trial_EN.tsv',sep ='\\t')['TEXT'])\n",
    "it_text = list(pd.read_csv('../data/CONcreTEXT_trial_IT.tsv',sep='\\t')['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(en_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bring up academic achievements , awards , and other milestones in your life . ', 'Please list people you have helped , your personal achievements , or troublesome times you have overcome . ', 'Add activated carbon straight to your vodka . ', 'Place sensors around your garden , and when a cat comes in , the motion activates a sensor . ', 'Look for a partner that shares your level of adventure in pursuing new types of experiences . ']\n",
      "['a loan with annual interest adds the interest rate ten times in ten years . ', \"If the roses are out of water even for a few minutes , they 'll suffer for it . \", 'Look at the woman whom you are listening to for as long as you or she is speaking . ', \"Hold the person 's hand when you cross the street . \", \"It 's no good trying to chase a lizard away when he still has dozens of places to hide . \"]\n",
      "# English words: 1471 \t # Italian Words: 1471\n"
     ]
    }
   ],
   "source": [
    "print(en_text[:5])\n",
    "random.shuffle(en_text)\n",
    "random.shuffle(it_text)\n",
    "print(en_text[:5])\n",
    "en_words = []\n",
    "it_words = []\n",
    "for sent in en_text:\n",
    "    for w in word_tokenize(sent):\n",
    "        en_words.append(w)\n",
    "    \n",
    "        \n",
    "for sent in it_text:\n",
    "    for w in word_tokenize(sent):\n",
    "        it_words.append(w)\n",
    "print(u'# English words: {} \\t # Italian Words: {}'.format(len(en_words),len(it_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = [w.lower() for w in en_words if w not in string.punctuation][:int(len(en_words)*.8)]\n",
    "en_test = [w.lower() for w in en_words if w not in string.punctuation][int(len(en_words)*.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_train = [w.lower() for w in it_words if w not in string.punctuation][:int(len(it_words)*.8)]\n",
    "it_test = [w.lower() for w in it_words if w not in string.punctuation][int(len(it_words)*.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Unigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('if', 'you'): 7, ('of', 'the'): 5, ('you', 'are'): 4, ('or', 'a'): 3, ('in', 'the'): 3, ('do', \"n't\"): 3, ('for', 'a'): 3, ('part', 'of'): 3, ('a', 'few'): 3, ('help', 'you'): 3, ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(nltk.bigrams(en_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_letters(train):\n",
    "    letters = []\n",
    "    for w in train:\n",
    "        letters.append('<s>')\n",
    "        for l in w:\n",
    "            letters.append(l)\n",
    "        letters.append('</s>')\n",
    "    return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_letters(en_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gram_prob(train):\n",
    "    train = to_letters(train)\n",
    "\n",
    "    total_letters = len(train)\n",
    "    unigrams = collections.defaultdict(lambda:0)\n",
    "    uni_freq = nltk.FreqDist(train)\n",
    "    \"\"\"\n",
    "    Unigram - p = c (w)/ N -> N = total number of letters (unigrams in corpus)\n",
    "    \"\"\"\n",
    "    for k,v in uni_freq.items():\n",
    "        unigrams[k] = v / float(total_letters)\n",
    "\n",
    "    \"\"\"\n",
    "    Bigram - p = c{w,w2}/c(w)\n",
    "    \"\"\"\n",
    "\n",
    "    bigrams = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "    bi_freq = nltk.FreqDist(nltk.bigrams(train))\n",
    "    for k, v in bi_freq.items():\n",
    "        bigrams[k] = v / uni_freq[k[0]]\n",
    "\n",
    "    #print(bi)\n",
    "\n",
    "    \"\"\"\n",
    "    Trigram - p = c(w,w2,w3)/c(w,w2)\n",
    "    \"\"\"\n",
    "\n",
    "    trigrams = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "    tri_freq = nltk.FreqDist(nltk.trigrams(train))\n",
    "    for k, v in tri_freq.items():\n",
    "        trigrams[k] = v / bi_freq[(k[0], k[1])]\n",
    "        \n",
    "    return unigrams,bigrams,trigrams\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test (a_models,b_models,test_set):\n",
    "    count = 0\n",
    "    uni_a = a_models[0]\n",
    "    uni_b = b_models [0]\n",
    "\n",
    "    bi_a = a_models[1]\n",
    "    bi_b = b_models[1]\n",
    "\n",
    "    tri_a = a_models[2]\n",
    "    tri_b = b_models[2]\n",
    "    scores = [0, 0, 0]\n",
    "    for word in test_set:\n",
    "\n",
    "        word = word.lower()\n",
    "        \"\"\"\n",
    "        0 - uni\n",
    "        1 - bi\n",
    "        2 - tri\n",
    "        \"\"\"\n",
    "        a_probs = [1, 1, 1]\n",
    "        b_probs = [1, 1, 1]\n",
    "\n",
    "\n",
    "\n",
    "        for letter in word:\n",
    "            \"\"\"\n",
    "           P(w) = P(c)*P(c-1)*P(c-n)\n",
    "            \"\"\"\n",
    "            if letter in uni_a.keys() and uni_b.keys():\n",
    "                a_probs[0] = a_probs[0]*uni_a[letter]\n",
    "                b_probs[0] = b_probs[0]*uni_b[letter]\n",
    "\n",
    "            elif letter in uni_a.keys():\n",
    "                a_probs[0] = a_probs[0] * uni_a[letter]\n",
    "                b_probs[0] = 0\n",
    "            elif letter in uni_b.keys():\n",
    "                a_probs[0] = 0\n",
    "                b_probs [0] = b_probs [0] * uni_b[letter]\n",
    "            else:\n",
    "                # No smoothing, if letter is not seen in the data set treat it as 0\n",
    "                a_probs[0] = 0\n",
    "                b_probs [0] = 0\n",
    "        if float(a_probs [0]) - float(b_probs [0]) > 0:\n",
    "            # adds +1 if a_score is higher than b_score\n",
    "            scores[0] += 1\n",
    "\n",
    "\n",
    "        bi = nltk.bigrams(['<s>']+ [l for l in word]+ ['</s>'])\n",
    "        tri = nltk.trigrams(['<s>']+ [l for l in word]+ ['</s>'])\n",
    "        for bigram in bi:\n",
    "            if bigram in bi_a.keys() and bigram in bi_b.keys():\n",
    "                a_probs[1] = a_probs[1]* bi_a[bigram]\n",
    "                b_probs[1] = b_probs[1] * bi_b[bigram]\n",
    "            elif bigram in bi_a.keys():\n",
    "                a_probs[1] = a_probs[1] * bi_a[bigram]\n",
    "                b_probs [1] = 0\n",
    "            elif bigram in bi_b.keys():\n",
    "                a_probs[1] = 0\n",
    "                b_probs[1] = b_probs[1] * bi_b[bigram]\n",
    "            else:\n",
    "                count += 1\n",
    "                a_probs [1] = 0\n",
    "                b_probs [1] = 0\n",
    "\n",
    "        if a_probs [1] - b_probs [1] > 0:\n",
    "            # adds +1 if a_score is higher than b_score\n",
    "            scores[1] += 1\n",
    "\n",
    "\n",
    "\n",
    "        for trigram in tri:\n",
    "            if trigram in tri_a.keys() and trigram in tri_b.keys():\n",
    "                a_probs[2] = a_probs[2]* tri_a[trigram]\n",
    "                b_probs[2] = b_probs[2] * tri_b[trigram]\n",
    "            elif trigram in tri_a.keys():\n",
    "                a_probs[2] = a_probs[2] * tri_a[trigram]\n",
    "                b_probs [2] = 0\n",
    "            elif trigram in tri_b.keys():\n",
    "                a_probs[2] = 0\n",
    "                b_probs[2] = b_probs[2] * tri_b[trigram]\n",
    "            else:\n",
    "                a_probs [2] = 0\n",
    "                b_probs [2] = 0\n",
    "\n",
    "        if a_probs [2] - b_probs [2] > 0:\n",
    "            # adds +1 if a_score is higher than b_score\n",
    "            scores[2] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    scores [0] = scores[0] / len(test_set)\n",
    "    scores [1] = scores[1] / len(test_set)\n",
    "    scores [2] = scores[2] / len(test_set)\n",
    "\n",
    "    print(count)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_it, bi_it, tri_it = gen_gram_prob(it_train)\n",
    "uni_eng,bi_eng,tri_eng = gen_gram_prob(en_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Unigram Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Unigrams English Vs. Italian: 51.8 %\n"
     ]
    }
   ],
   "source": [
    "eng_scores = run_test([uni_eng,bi_eng,tri_eng],[uni_it, bi_it, tri_it],en_test)\n",
    "print (u'Unigrams English Vs. Italian: {} %'.format(round(eng_scores[0]*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Bigram Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams English Vs. Italian: 77.7 %\n"
     ]
    }
   ],
   "source": [
    "print (u'Bigrams English Vs. Italian: {} %'.format(round(eng_scores[1]*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Trigram Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams English Vs. Italian: 66.19 %\n"
     ]
    }
   ],
   "source": [
    "print (u'Trigrams English Vs. Italian: {} %'.format(round(eng_scores[2]*100,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
